{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0549419f-5293-4654-83c8-1a7b1128db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a28e661-b84d-4504-bf18-5a7f56094423",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b71434b-82a3-48d9-9834-26181c1568b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature = 0.8)\n",
    "name = llm(\"I want to open a restaurant for Indian fodd. Suggest a fancy name for it.\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968590bb-4766-4172-bb4e-1d50b3de9610",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c5fefe-b41a-4afe-bacd-072389ea2c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restaurant for Mexican food. Suggest a fancy name for it.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# String Formatting\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fancy name for it.\"\n",
    ")\n",
    "\n",
    "prompt_template_name.format(cuisine = \"Mexican\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e209c70e-9806-4ca0-9373-ae6ce27c026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm = llm, promt = prompt_template_name)\n",
    "chain.run(\"Mexican\")\n",
    "# Here we do not need to set up sentence again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324393f8-3d44-4aeb-854f-d2fd91eb2a59",
   "metadata": {},
   "source": [
    "# Simple Sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "546f8c51-9fef-44f8-ab5c-511b765bd4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature = 0.8)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fancy name for it.\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm = llm, prompt = prompt_template_name)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template = \" suggest some menu items for {restaurant_name}. Return it comma separated.\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm = llm, prompt = prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09659be9-4009-418b-ac69-f600db37edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains = [name_chain, food_items_chain])\n",
    "response = chain.run(\"Indian\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2144185-e390-4c4d-ab58-45ec65f84513",
   "metadata": {},
   "source": [
    "# Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13d3f788-9adc-46cf-a851-997f8514225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature = 0.8)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fancy name for it.\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm = llm, prompt = prompt_template_name, output_key = \"restaurant_name\")\n",
    "\n",
    "llm = OpenAI(temperature = 0.8)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template = \"Suggest some menu items for {restaurant_name}.\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm = llm, prompt = prompt_template_items, output_key = \"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8b7d52-ffcd-48ac-995e-ef0cf5bfbad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.sequential import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [name_chain, food_items_chain],\n",
    "    input_variables = ['cuisine'],\n",
    "    output_variables = ['restaurant_name', 'menu_items']\n",
    ")\n",
    "\n",
    "chain({'cuisine': 'Arabic'})\n",
    "# will give input and both the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7101fd8-b8d6-480c-b5cf-78746291761e",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4355c177-2562-4079-8a62-c7e4f2c8380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm = llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent = Agent.Type.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose = True # To figure out internal steps\n",
    ")\n",
    "\n",
    "agent.run(\"When was Elon Musk born? What is his age rightnow in 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe596cde-635f-4451-8d36-85f8a61c07e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature = 0.8)\n",
    "\n",
    "# the tools we will give the agent access to.\n",
    "# llm-math tool uses an LLM\n",
    "tools = load_tools(['serpapi', \"llm-math\", llm = llm])\n",
    "\n",
    "# Initialize the agent with tools and language model\n",
    "# also initialize type of agent\n",
    "agent = intialize_agent(tools, llm, agent = AgemtType.ZERO_SHOT_REACT_DESCRIPTION, verbose = True)\n",
    "\n",
    "agent.run(\"What was the GDP of US in 2022 plus 5?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4346692e-e942-4455-bee2-74025a3caab8",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bfb3463-bebb-48cf-b1ba-41aec35b3d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default LLM Chain do not have memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea69e76-c9a6-4aaf-ab5d-b93c66a7455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm = llm, prompt = promt_template_name)\n",
    "name = chain.run(\"Mexican\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d5bb0d2-2419-48ae-8236-7186f8016f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can access memory by chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f9b56f-cde7-4799-ac8e-2e255d56ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationalBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "chain = LLMChain(llm = llm, prompt = prompt_template_name, memory = memory)\n",
    "name = chain.run(\"Mexican\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff72062-f766-4e3e-98cf-00f959a3e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.memory.buffer) \n",
    "# Human: Mexican\n",
    "# AI: Taco Fiesta\n",
    "# Human: Indian\n",
    "# AI: Maharaja's Palace Cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f2177-ff5d-42c9-b49c-3894bb503d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langhchain.chains import ConversationalChain\n",
    "\n",
    "convo = ConversationChain(llm = OpenAI(temperature = 0.8))\n",
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b297c69-9f67-4c8f-83a1-221c79d2faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ask question->\n",
    "convo.run(\"what is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b180b8-515f-43fc-9f59-89e304ad581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(convo.memory.buffer) # All the convo will get printed, it comes with default memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927d181-aa53-439d-a3f4-ba25481e5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k = 1)\n",
    "\n",
    "convo = ConversationChain(\n",
    "    llm = OpenAI(temperature = 0.8),\n",
    "    memory = memory\n",
    ")\n",
    "\n",
    "convo.run(\"Who won the first cricket world cup?\")\n",
    "# It will loss its memory after next question."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
